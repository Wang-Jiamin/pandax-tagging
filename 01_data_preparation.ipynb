# 01_数据准备和数据集类
"""
# 数据处理模块
这个notebook包含了数据加载、预处理和数据集的类定义。
"""

# %% [markdown]
# ## 1. 导入必要的库

# %%
import torch
import torch.nn as nn
import numpy as np
import random
import os
from torch.utils.data import Dataset, ConcatDataset, random_split, DataLoader
import glob

# %% [markdown]
# ## 2. 设置随机种子

# %%
def set_seed(seed=42):
    """设置随机种子以保证可重复性"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    print(f"随机种子已设置为: {seed}")

# 测试
set_seed(42)

# %% [markdown]
# ## 3. 数据集类定义

# %%
class Signal_Hit_Dataset_Awkward(Dataset):
    """加载.pt文件的数据集 - 修复版本"""
    
    def __init__(self, pt_file, normalize=True, log_transform=True, filter_empty=True):
        """
        Args:
            pt_file: .pt文件路径
            normalize: 是否归一化数据
            log_transform: 是否对area/height进行对数变换
            filter_empty: 是否过滤无效样本（推荐True）
        """
        self.pt_file = pt_file
        self.normalize = normalize
        self.log_transform = log_transform
        self.filter_empty = filter_empty
        
        # 加载.pt文件
        data = torch.load(pt_file, map_location='cpu')
        
        # 转换为tensor
        hits = torch.tensor(data['hits'], dtype=torch.float32)    # (n_samples, max_hits, 8)
        masks = torch.tensor(data['masks'], dtype=torch.bool)     # (n_samples, max_hits)
        labels = torch.tensor(data['labels'], dtype=torch.long)   # (n_samples,)
        max_hits = data.get('max_hits', hits.shape[1])
        
        print(f"加载PT文件: {pt_file}")
        print(f"  原始样本数: {len(hits)}")
        print(f"  最大hits数: {max_hits}")
        
        # === 关键修复：过滤无效样本 ===
        if self.filter_empty:
            valid_indices = []
            empty_samples = 0
            nan_samples = 0
            inf_samples = 0
            
            for i in range(len(hits)):
                sample_hits = hits[i]
                sample_mask = masks[i]
                
                # 检查1: 是否有NaN或Inf
                has_nan = torch.isnan(sample_hits).any().item()
                has_inf = torch.isinf(sample_hits).any().item()
                
                if has_nan:
                    nan_samples += 1
                    continue
                
                if has_inf:
                    inf_samples += 1
                    continue
                
                # 检查2: 是否有有效hits（mask=True的数量）
                valid_hits_count = sample_mask.sum().item()
                
                if valid_hits_count == 0:
                    empty_samples += 1
                    continue
                
                # 检查3: 有效hits是否有非零特征值
                valid_hits = sample_hits[sample_mask]
                
                # 检查所有特征是否都为0（异常情况）
                all_zeros = (valid_hits.abs() < 1e-8).all().item()
                if all_zeros:
                    empty_samples += 1
                    continue
                
                # 检查4: area和height是否都为0或负值（会导致对数变换问题）
                if self.log_transform:
                    area = valid_hits[:, 3]
                    height = valid_hits[:, 4]
                    
                    # 检查是否都是0或负值
                    area_all_nonpositive = (area <= 0).all().item()
                    height_all_nonpositive = (height <= 0).all().item()
                    
                    if area_all_nonpositive or height_all_nonpositive:
                        empty_samples += 1
                        continue
                
                # 通过所有检查，添加到有效样本
                valid_indices.append(i)
            
            # 过滤数据
            if valid_indices:
                valid_indices = torch.tensor(valid_indices, dtype=torch.long)
                self.hits = hits[valid_indices]
                self.masks = masks[valid_indices]
                self.labels = labels[valid_indices]
                
                print(f"  过滤后统计:")
                print(f"    有效样本: {len(self.hits)}")
                print(f"    空样本: {empty_samples}")
                print(f"    NaN样本: {nan_samples}")
                print(f"    Inf样本: {inf_samples}")
                print(f"    过滤比例: {(empty_samples+nan_samples+inf_samples)/len(hits)*100:.1f}%")
            else:
                print(f"  ⚠ 警告: 所有样本都被过滤了！")
                self.hits = hits
                self.masks = masks
                self.labels = labels
        else:
            self.hits = hits
            self.masks = masks
            self.labels = labels
        
        self.max_hits = max_hits
        
        # 计算归一化参数（基于过滤后的数据）
        if self.normalize:
            self._compute_normalization()
        
        # 打印标签分布
        self._print_label_distribution()
    
    def _compute_normalization(self):
        """计算归一化参数 - 基于有效样本"""
        # 只对有效hits（mask=True）计算统计量
        valid_indices = self.masks.nonzero(as_tuple=True)
        if len(valid_indices[0]) > 0:
            valid_hits = self.hits[valid_indices]
            
            self.mean = valid_hits.mean(dim=0)  # (8,)
            self.std = valid_hits.std(dim=0)    # (8,)
            self.std = torch.where(self.std < 1e-8, torch.tensor(1.0), self.std)
            
            print("归一化参数（基于有效样本）:")
            feature_names = ['rel_time', 'peak_time', 'width', 'area', 'height', 'x', 'y', 'array_id']
            for i, name in enumerate(feature_names):
                print(f"  {name:10s}: mean={self.mean[i]:.4f}, std={self.std[i]:.4f}")
        else:
            self.mean = torch.zeros(8)
            self.std = torch.ones(8)
            print("⚠ 警告: 没有有效hits用于计算归一化参数")
    
    def _print_label_distribution(self):
        """打印标签分布"""
        unique_labels, counts = torch.unique(self.labels, return_counts=True)
        label_names = {0: "S1", 1: "S2", 2: "unknown"}
        
        print("标签分布（过滤后）:")
        for label, count in zip(unique_labels, counts):
            name = label_names.get(label.item(), f"未知{label.item()}")
            percentage = count.item() / len(self.labels) * 100
            print(f"  {name}: {count.item()}个样本 ({percentage:.1f}%)")
    
    def __len__(self):
        return len(self.hits)
    
    def __getitem__(self, idx):
        """获取样本 - 安全版本"""
        hits = self.hits[idx].clone()  # (max_hits, 8)
        mask = self.masks[idx]         # (max_hits,)
        label = self.labels[idx]       # scalar
        
        # 安全检查
        if torch.isnan(hits).any() or torch.isinf(hits).any():
            print(f"警告: 样本 {idx} 包含NaN/Inf，使用安全值")
            hits = torch.where(torch.isnan(hits) | torch.isinf(hits), 
                              torch.zeros_like(hits), hits)
        
        # 对数变换（安全版本）
        if self.log_transform:
            # area (索引3) - 安全处理
            area = hits[:, 3]
            area_sign = torch.sign(area)
            area_abs = torch.abs(area)
            area_abs = torch.clamp(area_abs, min=1e-8)  # 避免0
            hits[:, 3] = area_sign * torch.log1p(area_abs)
            
            # height (索引4) - 安全处理
            height = hits[:, 4]
            height_sign = torch.sign(height)
            height_abs = torch.abs(height)
            height_abs = torch.clamp(height_abs, min=1e-8)
            hits[:, 4] = height_sign * torch.log1p(height_abs)
        
        # 归一化（安全版本）
        if self.normalize and hasattr(self, 'mean'):
            # 确保std不为0
            std_safe = torch.where(self.std < 1e-8, torch.ones_like(self.std), self.std)
            hits = (hits - self.mean) / std_safe
        
        # 裁剪极端值
        hits = torch.clamp(hits, -5, 5)
        
        # 确保填充位置为0
        hits[~mask] = 0.0
        
        return {
            "hits": hits,
            "mask": mask,
            "label": label,
        }

# %% [markdown]
# ## 4. 测试数据集类

# %%
# 测试代码
def test_dataset():
    """测试数据集类的功能"""
    # 创建一个虚拟的PT文件数据用于测试
    dummy_data = {
        'hits': torch.randn(100, 50, 8).numpy(),  # 100个样本，每个最多50个hits，8个特征
        'masks': torch.ones(100, 50, dtype=torch.bool).numpy(),
        'labels': torch.randint(0, 3, (100,)).numpy(),
        'max_hits': 50
    }
    
    # 保存临时文件
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.pt', delete=False) as f:
        temp_path = f.name
        torch.save(dummy_data, temp_path)
    
    print("="*50)
    print("测试数据集类:")
    print("="*50)
    
    # 创建数据集
    dataset = Signal_Hit_Dataset_Awkward(
        pt_file=temp_path,
        normalize=True,
        log_transform=True
    )
    
    # 测试获取单个样本
    sample = dataset[0]
    print(f"\n样本形状:")
    print(f"  hits: {sample['hits'].shape}")
    print(f"  mask: {sample['mask'].shape}")
    print(f"  label: {sample['label']}")
    
    # 测试DataLoader
    loader = DataLoader(dataset, batch_size=16, shuffle=True)
    batch = next(iter(loader))
    print(f"\n批次形状:")
    print(f"  hits: {batch['hits'].shape}")
    print(f"  mask: {batch['mask'].shape}")
    print(f"  labels: {batch['label'].shape}")
    
    # 清理临时文件
    import os
    os.unlink(temp_path)
    
    return dataset

# 运行测试
test_dataset()
